FROM fluxcapacitor/package-tensorflow-7a7fe93-4c0052d-gpu:master

WORKDIR /root

COPY lib/ lib/

RUN \
  cd ~/lib/jni \
  && ln -s ~/lib/jni/libtensorflow_jni-gpu.so libtensorflow_jni.so

ENV \
  TF_CPP_MIN_LOG_LEVEL=0

RUN \
  mkdir -p /root/logs

ENV \
  LOGS_HOME=/root/logs

RUN \
  echo "deb https://dl.bintray.com/sbt/debian /" | tee -a /etc/apt/sources.list.d/sbt.list \
  && apt-key adv --keyserver hkp://keyserver.ubuntu.com:80 --recv 2EE0EA64E40A89B84B2DF73499E82A75642AC823 \
  && apt-get update \
  && apt-get install -y sbt

COPY src/ src/
COPY build.sbt build.sbt
COPY scripts/ scripts/

ENV \
  PATH=/root/scripts:$PATH

RUN \
  sbt clean clean-files package 

ENV \
  PIO_MODEL_SERVER_PATH=/root/src/main/python

ENV \
  PIO_MODEL_SERVER_PORT=9876 

ENV \
  PIO_MODEL_SERVER_PROMETHEUS_PORT=8080

ENV \
  PIO_MODEL_SERVER_TENSORFLOW_SERVING_PORT=9000

ENV \
  PIO_MODEL_SERVER_TENSORFLOW_SERVING_REQUEST_BATCHING=true

# We're installing (duplicate of base Docker image) 
#   in order to force an error during the Docker build 
#   if/when the base Docker image changes TF version.
# When the base Docker image changes TF version, be sure 
#   to propagate this change to the following:
#     src/main/python/model/requirements_pio_model_server.txt
RUN \
  pip install /tmp/pip/tensorflow-1.2.0rc2-cp35-cp35m-linux_x86_64.whl \
  && pip uninstall -y /tmp/pip/tensorflow-1.2.0rc2-cp35-cp35m-linux_x86_64.whl

RUN \
  conda create --yes -n model_environment_python3 python=3.5 

RUN \
  create_model_server_environment_python3

ENV \
  PIO_MODEL_STORE_HOME=/root/volumes/source.ml/prediction.ml/model_store

COPY run run

## HACK until new base package/tensorflow-...-gpu images are built
#RUN \
#  cd /usr/local/nvidia/lib64/ \
#  && ln -s /usr/local/cuda-8.0/targets/x86_64-linux/lib/stubs/libcuda.so libcuda.so.1
#RUN \
#  ldconfig /usr/local/cuda/lib64

EXPOSE 9876 9000 9040 8080

CMD ["supervise", "."]
